# NLP系列01——基础篇：序列模型sequence

## 什么是sequence

现实生活中很多事情的发生，是有前因后果关系的，也就是时序结构  

比如：
1. 汽车的评价会随时间变化而变化，例如新品刚上市时宣发做得好，评价高，各方面优于竞品，评分上升，出现负面报道，评分下降
2. 大地震后发生小余震的概率很大
3. 人的对话是有前后关系的

## 统计学上的解释

在时间t观察到$x_t$，那么T个**不独立**的随机变量$(x_1,...,x_T)~p(x)$  
使用条件概率展开$p(a,b)=p(a)p(b|a)=p(b)p(a|b)$

注意这里是不独立的随机变量，和一般机器学习中用的独立变量有区别

正序：
$p(x)=p(x_1)*p(x_2|x_1)*p(x_3|x_1,x_2)*...*p(x_T|x_1,...,X_{T-1})$
逆序：
$p(x)=p(x_T)*p(x_{T-1}|x_T)*p(x_{T-2}|x_{T-1},x_T)*...*p(x_1|x_2,...,X_T)$

## 序列模型

对条件概率建模  
$p(x_t|x_1,...,x_{t-1})=p(x_t|f(x_1,...,x_{t-1}))$

### 马尔科夫假设

假设当前数据只和$\tau$个过去数据点相关

$p(x_t|x_1,...,x_{t-1})=p(x_t|x_{t-\tau},...,x_{t-1})=p(x_t|f(x_{t-\tau},...,x_{t-1}))$

例如在过去的数据上训练一个MLP模型

### 潜变量模型

引入一个潜变量$h_t$ 来表示过去信息 $h_t=f(x_1,...,x_{t-1})$ ，这样$x_t=p(x_t|h_t)$，这里$h_t$可以是一个向量或者一个数

$$
\begin{CD}
    h @>a>> h' \\
    @VVV a/  @VV b V \\
    x @>>b> x' \\
\end{CD}
$$

其中a表示一个模型，输入h与x输出h'，b表示另一个模型，输入x与h'输出x'

## 总结

时序模型中，当前数据跟之前观察到的数据项相关  
自回归模型使用自身过去数据来预测未来
马尔科夫模型假设当前只跟最近少数数据相关，从而简化模型
潜变量模型使用一个变量（潜变量）来概括历史信息